Random Forest:
  criterion:
    - gini
    - entropy
  max_depth:
    - 6
    - 8
  min_samples_leaf:
    - 7
    - 10
  n_estimators:
    - 400
    - 500

Decision Tree:
  criterion:
    - gini
    - entropy
  max_depth:
    - 6
    - 8
  min_samples_leaf:
    - 7
    - 10

Logistic Regression:
  C:
    - 0.1
    - 1
    - 10
    - 100
  solver:
    - newton-cg
    - lbfgs
    - liblinear
    - sag
    - saga
  max_iter:
    - 100
    - 200

XGBoost:
  n_estimators:
    - 400
    - 500
  max_depth:
    - 7
    - 9
  learning_rate:
    - 0.1
    - 0.2
  gamma:
    - 0
    - 0.1
    - 0.2
    - 0.3
  reg_alpha:
    - 0
    - 0.01
    - 0.1
  reg_lambda:
    - 1
    - 0.1
    - 0.01

# MLP:
#   hidden_layer_sizes:
#     - (50,)
#     - (100,)
#     - (100, 50)
#     - (50, 100)
#     - (100, 100)
#   activation:
#     - relu
#     - tanh
#     - logistic
#   solver:
#     - adam
#     - sgd
#     - lbfgs
#   alpha:
#     - 0.0001
#     - 0.001
#     - 0.01
#     - 0.1
#   learning_rate:
#     - constant
#     - adaptive
#   max_iter:
#     - 200
#     - 500
#     - 1000
#   early_stopping:
#     - True
#     - False
